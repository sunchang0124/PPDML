{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Privacy-preserving Linear Regression (PPLR) -Secure multiparty computation techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This notebook shows how to do privacy-preserving linear regression in the scenario that data is vertically partitioned. \n",
    "* The following code is based on two data parties having the same data instances but different features/attributes/variables. \n",
    "* It can be easily extended to more than two data parties. \n",
    "* We assume data parties are both semi-honest which means they will follow the protocol but still curious about each other's data.\n",
    "* Data parties only learn the outcome of linear regression which is y = b1x + b0 (b1:coefficient, b0:intercept)\n",
    "* We use Ordinary Least Squares (OLS): minimizing the sum of the squares of the differences between the observed dependent variable (values of the variable being predicted) in the given dataset and those predicted by the linear function. \n",
    "* If you need more mathematical knowledge of OLS, please read: https://en.wikipedia.org/wiki/Ordinary_least_squares\n",
    "* This code applied secure scalar product protocol from: https://dl.acm.org/citation.cfm?id=775142 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model, datasets\n",
    "from numpy.linalg import inv\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"matrix.JPG\" width=\"500\" height=\"500\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# If you know OLS in linear regression, then you can understand the problem we are solving is \n",
    "# b1 = (X.T * X)-1 * X.T * Y  The challenging part is how to calculate X_a * X_b without disclosing original data.\n",
    "# This problem can be solved by secure scalar product which is one of secure multiparty computation techniques.\n",
    "# Please see the picture below.\n",
    "Image(url= \"matrix.JPG\", width=500, height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use one dataset from Scikit Learn. For you to try this code, this dataset is the easiest way to get and run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Load the diabetes dataset from Sklearn\n",
    "# diabetes = datasets.load_diabetes()\n",
    "# df = pd.DataFrame.from_records(diabetes.data)\n",
    "# col = ['feature0', 'feature1', 'feature2', 'feature3', 'feature4', 'feature5',\\\n",
    "#       'feature6', 'feature7', 'feature8', 'target']\n",
    "# df.columns = col\n",
    "\n",
    "# ### Make a centralized dataset which will be used to test whether our PPLR\n",
    "# X_centralized = df.drop(['target'], axis=1)\n",
    "# Y = df['target']\n",
    "# B_divide_set = 17 # need to be a divisor of the number of instances (try function divisor)\n",
    "# print('The number of rows:', len(df))\n",
    "# print('The number of features:', len(col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "myDataA=pd.read_csv(\"https://raw.githubusercontent.com/sunchang0124/PPDML/master/Privacy-preserving%20bayesians/preprocessed_dataFile_A.csv\")\n",
    "myDataB=pd.read_csv(\"https://raw.githubusercontent.com/sunchang0124/PPDML/master/Privacy-preserving%20bayesians/preprocessed_dataFile_B.csv\")\n",
    "colA = myDataA.columns\n",
    "colB = myDataB.columns\n",
    "myDataA = myDataA.drop('Unnamed: 0', axis=1)\n",
    "Y = myDataB['diag_3']\n",
    "myDataB = myDataB[colB[0:6]].drop(['Unnamed: 0'], axis=1)    \n",
    "\n",
    "X_centralized = np.concatenate((myDataA, myDataB.drop('diag_3', axis=1)), axis=1)\n",
    "B_divide_set = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We simulate the vertically partitioned data scenario so that dataset is splited into two sets for two data parties. \n",
    "* Data Site A: feature 0 to feature 4\n",
    "* Data Site B: feature 5 to feature 8 + target feature (feature 9)\n",
    "* Please note that the target class is only available at Data Site B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data site A ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_a = myDataA # df[col[0:5]] # feature0 - feature4 # myDataA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Add one columns with all values of 1 to dataset which uses to calculate b0\n",
    "b0 = np.ones((1, len(X_a))).tolist()[0]\n",
    "X_a.insert(loc=0, column='b0', value=b0)\n",
    "\n",
    "# Calculate X_a.T * X_a locally at data site A \n",
    "XaTXa = np.matrix(X_a).T * np.matrix(X_a)\n",
    "len_A = len(X_a.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random numbers and add to data at Data Site A\n",
    "A_randoms = []\n",
    "for i in range(0, len_A):\n",
    "#     np.random.seed(1)\n",
    "    A_randoms.append(np.random.randint(0,5, len(X_a.iloc[:,i])))\n",
    "    \n",
    "C_matrix = [] # C_noises is shared between A and B \n",
    "for i in range(0, len_A):\n",
    "#     np.random.seed(2)\n",
    "    C_matrix.append(np.random.randint(0,5, (len(X_a.iloc[:,i]), len(X_a.iloc[:,i]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_noises_A = [] # which will be sent to B\n",
    "for i in range(0, len_A):\n",
    "    Sum_noises_A.append(np.add(X_a.iloc[:,i], np.dot(C_matrix[i], A_randoms[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('C_matrix.npy', C_matrix)\n",
    "C_matrix = np.load('C_matrix.npy')\n",
    "\n",
    "np.save('Sum_noises_A.npy', Sum_noises_A)\n",
    "Sum_noises_A = np.load('Sum_noises_A.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Site A: send __C_matrix__ and __Sum_noises_A__ and __A_randoms_Sumset__ to Data Site B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data site B ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_b = myDataB # df[col[5:10]] # feature5 - feature8 and target feature # myDataB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "XbTXb = np.matrix(X_b).T * np.matrix(X_b)\n",
    "len_B = len(X_b.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sum_coef_B = []\n",
    "for i in range(0, len_B):\n",
    "    Sum_noises_temp = []\n",
    "    for j in range(0, len_A):\n",
    "        Sum_noises_temp.append(np.dot(C_matrix[j].transpose(), X_b.iloc[:,i])) \n",
    "    Sum_coef_B.append(Sum_noises_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_random_set = []\n",
    "for i in range(0, len_A):\n",
    "#     np.random.seed(3)\n",
    "    B_random_set.append(np.random.randint(0,5, int(len(X_b.iloc[:,0])/B_divide_set))) \n",
    "\n",
    "Sum_noises_B = [] # which will be send to A\n",
    "for n in range(0, len_B):\n",
    "    B_noise = []\n",
    "    for i in range(0, len_A):\n",
    "        B_random_inter = []\n",
    "        for j in range(0, len(B_random_set[i])): \n",
    "            for k in range(0, B_divide_set):\n",
    "                B_random_inter.append(B_random_set[i][j])\n",
    "        B_noise.append(Sum_coef_B[n][i] + B_random_inter)\n",
    "    Sum_noises_B.append(B_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add noises dataset A to the dataset B\n",
    "Sum_noises_AB = []\n",
    "for i in range(0, len_B):\n",
    "    Sum_noises_temp = []\n",
    "    for j in range(0, len_A):\n",
    "        Sum_noises_temp.append(np.dot(Sum_noises_A[j], X_b.iloc[:,i])) # X_b[:,i]\n",
    "    Sum_noises_AB.append(Sum_noises_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Sum_noises_B.npy', Sum_noises_B)\n",
    "Sum_noises_B = np.load('Sum_noises_B.npy')\n",
    "np.save('Sum_noises_AB.npy', Sum_noises_AB)\n",
    "Sum_noises_AB = np.load('Sum_noises_AB.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B sends __Sum_noises_B__ and __Sum_noises_AB__ to A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Data Site A ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "A_randoms_Sumset = []\n",
    "for i in range(0, len_A):\n",
    "    sum_temp = []\n",
    "    for j in range(0, int(len(X_a)/B_divide_set)):\n",
    "        temp = 0\n",
    "        for k in range(0, B_divide_set):\n",
    "            temp = temp + A_randoms[i][B_divide_set*j + k]\n",
    "        sum_temp.append(temp)\n",
    "        \n",
    "    A_randoms_Sumset.append(sum_temp)\n",
    " \n",
    "    \n",
    "Sum_noises_B_Arand = []\n",
    "for n in range(0, len_B):\n",
    "    temp = []\n",
    "    for i in range(0, len_A):\n",
    "        temp.append(np.subtract(Sum_noises_AB[n][i], np.dot(A_randoms[i],Sum_noises_B[n][i])))\n",
    "    Sum_noises_B_Arand.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('A_randoms_Sumset.npy', A_randoms_Sumset)\n",
    "A_randoms_Sumset = np.load('A_randoms_Sumset.npy')\n",
    "\n",
    "np.save('Sum_noises_B_Arand.npy', Sum_noises_B_Arand)\n",
    "Sum_noises_B_Arand = np.load('Sum_noises_B_Arand.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A sends __A_randoms_Sumset__ and __Sum_noises_B_Arand__ back to B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to Data Site B --> As B has the target feature, B calculate the final results ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_sums = []\n",
    "for i in range(0, len_A):\n",
    "    r_sum = 0\n",
    "    for j in range(0, len(B_random_set[0])):\n",
    "        r_sum = r_sum + A_randoms_Sumset[i][j] * B_random_set[i][j]\n",
    "    rand_sums.append(r_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes = []\n",
    "for n in range(0, len_B):\n",
    "    out = []\n",
    "    for i in range(0, len_A):\n",
    "        out.append(Sum_noises_B_Arand[n][i] + rand_sums[i])  #Sum_noises_AB[n][i] - \n",
    "    outcomes.append(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine matrix to compute linear regresssion (b1 and b0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "XaTXb = np.matrix(outcomes)[:-1]\n",
    "\n",
    "XbTXa = XaTXb.T\n",
    "\n",
    "XaTY = np.matrix(outcomes)[-1]\n",
    "\n",
    "XbTXb_exclY = XbTXb[:-1].T[:-1]\n",
    "\n",
    "XbTY = np.delete(XbTXb[-1], -1)\n",
    "\n",
    "pp_XTX = np.concatenate((np.concatenate((XaTXa, XbTXa), axis=1), np.concatenate((XaTXb, XbTXb_exclY), axis=1)),axis=0) \n",
    "pp_XTY = np.concatenate((XaTY, XbTY),axis=1).T\n",
    "\n",
    "pp_out = np.linalg.inv(pp_XTX) * pp_XTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [[  5.51451255]\n",
      " [-12.43600734]\n",
      " [-13.60236922]\n",
      " [ -0.11782703]\n",
      " [  1.8613011 ]\n",
      " [  0.3361196 ]\n",
      " [ -0.24537211]\n",
      " [  1.5963641 ]\n",
      " [ -0.91016081]\n",
      " [  0.03021797]\n",
      " [ 20.91553868]\n",
      " [ -4.20045788]\n",
      " [ -0.04897685]\n",
      " [  0.04809015]]\n",
      "Intercept:  364.3401128950095\n"
     ]
    }
   ],
   "source": [
    "b1 = pp_out[1:]\n",
    "b0 = pp_out.item(0)\n",
    "print('Coefficients: \\n' ,b1)\n",
    "print('Intercept: ', b0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking with the centralized data/method ####\n",
    "Scikit learn linear regression method is used to compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: \n",
      " [  5.51451255 -12.43600734 -13.60236922  -0.11782703   1.8613011\n",
      "   0.3361196   -0.24537211   1.5963641   -0.91016081   0.03021797\n",
      "  20.91553868  -4.20045788  -0.04897685   0.04809015]\n",
      "Intercept: \n",
      " 364.340112895\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression(fit_intercept=True, normalize=True)\n",
    "regr.fit(X_centralized, Y)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "print('Intercept: \\n', regr.intercept_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
